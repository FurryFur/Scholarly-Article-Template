<h1 data-label="852589" class="ltx_title_section">Evaluation</h1><div>We evaluate our model using a panel of [number of evaluators] human judges. Evaluation covers four different criteria, sound effect interpretability, sound effect diversity, condition matching and overall sound effect quality.&nbsp;</div><div></div><div>Our     interpretability&nbsp;test is designed to evaluate whether the generator is able to produce sounds that are immediately recognizable. This is an important quality for sound effects, as they are used, along with special effects, to sell a particular action in game. If the sound effects are not immediately recognizable, they may not be able to adequately sell an effect and may instead create a disconnect between between what the player is hearing, and what is happening in game. To evaluate     interpretability, for each judge, we draw ten random examples from the generator and ask the judges to label each example with their perceived interpretation of what the sound effect represents. Afterwards, judges are shown the true set of conditioning texts associated with each example. Each judge then subjectively decides whether they correctly labeled each example. We leave this decision up to the judges, as perceived correctness is more important than exact matches when it comes to int</div><div></div>