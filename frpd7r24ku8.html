<h1 data-label="852589" class="ltx_title_section">Evaluation</h1><div>We evaluate our model using a panel of [number of evaluators] human judges. Evaluation covers four different criteria, sound effect readability, sound effect diversity, condition matching and overall sound effect quality. Our readability test is designed to evaluate whether the generator is able to produce sounds that are immediately recognizable. This is an important quality for sound effects, as they are ment For each judge, we draw ten random examples from the generator and ask the judges to label each example with their perceived interpretation of what the sound effect represents.&nbsp;</div><div>[In batches of ten random examples,  we ask annotators to label which digit they perceive in each example, and compute their accuracy  with respect to the classifierâ€™s labels (random accuracy would be 10%). After the ten questions, each  annotator is asked to assign subjective values of 1 through 5 for criteria of sound quality, ease of  intelligibility, and speaker diversity. ]</div>