<h2 data-label="752902" class="ltx_title_subsection">Interpretability</h2><div>Our baseline interpretability on the real dataset comes out at 72%, while interpretability on the generated sound effects comes out at 62%. We note that these values are somewhat artificially decreased over what they should be, due to our conditioning text dataset containing several single keywords that do not, on their own, describe the sounds they are paired with. Examples are keywords like 'hard', 'low' and 'fast', which we observed frequently while performing the interpretability tests with judges. When these keywords appear, judges are forced to mark their guessed keywords as incorrect, even when it may be clear what the sound effect actually represents. However, since these keywords appear as true labels in both the real and generated interpretability tests, the comparison should still be fair. Our high interpretability can be put down&nbsp;</div>