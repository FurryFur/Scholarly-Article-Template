<div>Currently, the available sound effect generators for games produce only 8 bit retro style sound effects and are not suitable for use in any other genres of games. Given the importance of good sound effects to the overall experience of a game and the lack of highly skilled sound engineers in the indie development space, we explore new avenues for sound effect generation that are able to produce sound effects for a wider range of genres, without the need of any technical expertise. We produce a novel neural network model that is able to produce short snippets of audio similar to those present in whatever dataset it is trained on. In addition we add the ability to enter conditional text into the model and retrieve a corresponding generated sound effect out. Our results show that users are able to generate  sound effects, that match their user entered conditioning text with a probability of above 50%. We also observe a high quality and interpretability of sound effects. However, increasing the s</div><div>While voice, image and text synthesis are heavily studied areas in the field of machine learning, applications of generative models in the area of sound effect synthesis has received relatively little attention. This paper aims to be a proof of concept demonstrating the possibility of synthesizing game ready sound effects from an input text description using machine learning models. Using a Generative Adversarial Network model we are able to synthesis believable sound effects from text. We observe that the model is able to reproduce simple sounds, such as hitting and footsteps, with a good degree of believability. We also observe that synthesized sound effects match the supplied conditioning text to produce the correct sound effect. More complex sound effects such as human vocalizations can be generated by training the model on a targeted dataset of sound effects that cover a more limited number of categories include the target.</div>