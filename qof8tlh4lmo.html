<h1 data-label="148606" class="ltx_title_section">Model</h1><div></div><div>Our model builds heavily on the WaveGAN architecture by [Author names here][Reference here]. The original WaveGAN implementation ported the DCGAN [Reference to original DCGAN paper] architecture to 1D to work with audio data. We replace the existing 1D DCGAN model with our own model, heavily inspired by Progressive GAN [paper reference]. We also extend the model to support conditioning text, taking heavy inspiration from StackGAN's [paper reference] text conditioning implementation. StackGAN's model uses text embeddings, which are downsampled to 128 dimensions, however, the embedding model used is not specified. We choose to use ELMo [Reference] for our text embedding for the reasons stated in section (<span class="au-ref raw v1">\ref{151756}</span>).&nbsp;</div><div></div><div>We extend the original Progressive GAN model [reference] by replacing pairs of convolutions with residual blocks, containing two convolutions and one skip connection each (Fig.&nbsp;<span class="au-ref raw v1">\ref{801834}</span>) We use similar residual blocks to those used in the Improved Training of Wasserstein GANs paper [Reference] [figure]. We stick to the pre-activation scheme used in the paper as it has been previously shown to give better results than other activation schemes [Reference, see&nbsp;<a href="https://medium.com/@14prakash/understanding-and-implementing-architectures-of-resnet-and-resnext-for-state-of-the-art-image-cc5d0adf648e">https://medium.com/@14prakash/understanding-and-implementing-architectures-of-resnet-and-resnext-for-state-of-the-art-image-cc5d0adf648e</a>]. Our residual block scheme is shown in figure&nbsp;<span class="au-ref raw v1">\ref{801834}</span>.</div><div></div><div>We implement progressive growing by giving each up and down block an amount that it is turned on by. This amount is determined by the current  level of detail (audio LOD) that the model is  being trained at (see fig.&nbsp;<span class="au-ref raw v1">\ref{471330}</span>). Progressive growing allows us to first learn lower frequency information about sound effects The output of the 'to audio' layer after the first residual block in the generator, constitutes the first audio LOD (fig.&nbsp;<span class="au-ref raw v1">\ref{471330}</span>). Each up and down block can either be in one of three modes. Fully off, in which case we treat the layer as a skip connection, implemented by a simple nearest neighbor, or average downsample for up and down blocks respectively. Fully on, in which case the skip connection is ignored and the layer becomes a residual block. Or partially on, which occurs during LOD transitioning. In this case we linearly interpolate between the output of the skip connection, and residual block&nbsp;</div>