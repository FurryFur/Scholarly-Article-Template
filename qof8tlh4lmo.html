<h1 data-label="148606" class="ltx_title_section">Model</h1><div></div><div>Our model builds heavily on the WaveGAN architecture by [Author names here][Reference here]. The original WaveGAN implementation ported the DCGAN [Reference to original DCGAN paper] architecture to 1D to work with audio data. We replace the existing 1D DCGAN model with our own model, heavily inspired by Progressive GAN [paper reference]. We also extend the model to support conditioning text, taking heavy inspiration from StackGAN's [paper reference] text conditioning implementation. StackGAN's model uses text embeddings, which are downsampled to 128 dimensions, however, the embedding model used is not specified. We choose to use ELMo [Reference] for our text embedding for the reasons stated in section (<span class="au-ref raw v1">\ref{151756}</span>).&nbsp;</div><div></div><div>We extend the original Progressive GAN model [reference] by replacing pairs of convolutions with residual blocks, containing two convolutions and one skip connection each (Fig.&nbsp;<span class="au-ref raw v1">\ref{801834}</span>) We use similar residual blocks to those used in the Improved Training of Wasserstein GANs paper [Reference] [figure]. We stick to the pre-activation scheme used in the paper as it has been previously shown to give better results than other activation schemes [Reference, see&nbsp;<a href="https://medium.com/@14prakash/understanding-and-implementing-architectures-of-resnet-and-resnext-for-state-of-the-art-image-cc5d0adf648e">https://medium.com/@14prakash/understanding-and-implementing-architectures-of-resnet-and-resnext-for-state-of-the-art-image-cc5d0adf648e</a>]. Our residual block scheme is shown in figure&nbsp;<span class="au-ref raw v1">\ref{801834}</span>.</div><div></div><div> Progressive growing allows our model to first learn how to generate simpler, lower frequency versions of sound effects in the dataset, then progressively adds higher frequency detail as the model grows.  &nbsp;We implement progressive growing by giving each up and down block an amount that it is turned on by. This amount is determined by the current  level of detail (audio LOD) that the model is  being trained at (see fig.&nbsp;<span class="au-ref raw v1">\ref{471330}</span>).     The output of the 'to audio' layer after the first residual block in the generator, constitutes the first audio LOD, and consists of only sixteen samples (fig.&nbsp;<span class="au-ref raw v1">\ref{471330}</span>).    Each up and down block can either be in one of three modes. Fully off, in which case we treat the layer as a skip connection, implemented by a simple nearest neighbor, or average downsample for up and down blocks respectively. Fully on, in which case the skip connection is ignored and the layer becomes a residual block. Or partially on, which occurs during LOD transitioning. In this case we linearly interpolate between the output of the skip connection, and the output of the residual block. Since the generator and discriminator mirror each other, once the a generated signal has passed the current LOD layer in the generator, it will then skip then essentially skip the rest of the generator layers and be passed thgrouSee figures&nbsp;<span class="au-ref raw v1">\ref{471330}</span> and&nbsp;<span class="au-ref raw v1">\ref{801834}</span> for a detailed overview our architecture.</div>