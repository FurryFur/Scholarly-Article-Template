<h1 data-label="956325" class="ltx_title_section">Training Data</h1><div>Our training data comes from several different sound effect libraries, purchased from&nbsp;A Sound Effect[Reference], which we unfortunately cannot make publicly available. We opted to use commercial sound effects over publicly available ones due to their easy access, consistent audio quality and generally high quality metadata. We trained two main models for this paper. We use the smaller Articulated Magic Elements dataset as the training dataset for the main evaluation of our model. This dataset provides several distinct modalities, whiles also constraining the modalities to fit withing the category of magic. This allows our generator to generate higher quality output, as less modalities need to be covered. The distinct sub-categories of ice, wind, earth, fire, air, and black still provide an interesting The seven sound effect libraries used were: Animal HyperRealism[Reference], Articulated Magic Elements[Reference], Eclectic Whooshes[Reference], Gamemaster Audio - Pro Sound Collection[Reference], Lethal Energies[Reference], Polarity[Reference] and Swordfighter[Reference]. All these libraries can be found over at A Sound Effect[Reference], with sample audio available. Owing to the fact that we can only produce just over one second of audio, we first     preprocess the training audio by splitting audio clips on silent intervals, then discarding any audio clips that are longer than our network can produce. Our final dataset consists of 6,883 sound effects, which is still relatively small. In order to augment this dataset, we apply a small pitch shift at training time, similar to what is done in games to disguise repeated sound effects and make each sound effect sound unique.&nbsp;</div>