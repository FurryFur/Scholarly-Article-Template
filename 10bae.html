<h1 data-label="687807" class="ltx_title_section">Future Research</h1><h2 data-label="865239" class="ltx_title_subsection">Failure Cases</h2><div>We observe a number of failure cases in our present model which would be interesting areas of future research. Our first observation is that our present model is unable to capture long range dependencies. These include long range frequency changes, such as power-up sounds, which typically increase in pitch as time increases [compare generated to real waveforms].&nbsp; [To check: keyboard typing - gaps between audio events]. Our model also has trouble with layered sound effects. The presence of layered signals presents an interesting distinction between audio and image data, which GANs were originally designed to generate. Image data typically contains less layered signals than audio data. Although image data can contain layered signals where the image contains reflections and transparency, there are typically only two or three signal layers in these cases, whereas audio data typically contains many overlapping signals. Sound effects especially are typically built up by layering different sounds on top of one another to produce rich and expressive audio signals. We find that our generative model has a tendency to produce somewhat muddy audio signals, which do not contain clearly distinguishable sets of audio signals. An interesting area of future research would be to try to create a network that can produce a varying number of outputs, with each output corresponding to a separate audio layer. These audio layers could then be combined to produce the final output signal. In order to do this we would first need to pre-process the training audio to split all audio signals into&nbsp;</div>