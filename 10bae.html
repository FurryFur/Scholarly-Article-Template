<h1 data-label="687807" class="ltx_title_section">Future Research</h1><h2 data-label="865239" class="ltx_title_subsection">Failure Cases</h2><div>We observe a number of failure cases in our present model which would be interesting areas of future research. Our first observation is that our present model is unable to capture long range dependencies. These include long range frequency changes, such as power-up sounds, which typically increase in pitch as time increases [compare generated to real waveforms].&nbsp; [To check: keyboard typing - gaps between audio events]. </div><div></div><div>Our model also has trouble generating layered sound effects. The presence of layered signals in audio data presents an interesting distinction from the image data . Image data typically contains less layered signals than audio data. Although image data can contain layered signals where the image contains reflections and transparency, there are typically only two or three signal layers in these cases, whereas audio data typically contains many overlapping signals. Sound effects especially are typically built up by layering different sounds on top of one another to produce rich and expressive audio signals. We find that our generative model has a tendency to produce somewhat muddy audio signals, which do not contain clearly distinguishable audio layers. An interesting area of future research would be to try to create a network that can produce a varying number of outputs, with each output corresponding to a separate audio signal. These audio signals would then be combined to produce the final output signal. In order to do this we would first need to perform blind signal separation on the training data in order to separate out individual source signals from the original mixed signals.</div>